{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdpa-sU8xeLo",
        "outputId": "c998021f-6c28-4dc9-bbd3-29fe15602995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun  2 23:44:49 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0             49W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# GPU check\n",
        "!nvidia-smi                                             # should list a Tesla card\n",
        "\n",
        "# === 1.1  Pick ONE of the two blocks below ===\n",
        "\n",
        "# A) Use a compatible Torch that still contains _accumulate (simplest)\n",
        "!pip install -q torch==2.2.0+cu118 torchvision==0.17.0+cu118 \\\n",
        "               --extra-index-url https://download.pytorch.org/whl/cu118  # :contentReference[oaicite:0]{index=0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfEOZpKf6noA",
        "outputId": "73c2b878-e8e0-4fd6-f32c-be9b65f940ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PD-LlCbK6yVA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/crops.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('crops')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ToDvneL6Cvt",
        "outputId": "638201b2-fa28-4350-ea85-40ebad8bb4d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deep-text-recognition-benchmark' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: '/content/deep-text-recognition-benchmark # %cd persists in Colab sessions :contentReference[oaicite:2]{index=2}'\n",
            "/content\n",
            "sed: can't read dataset.py: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/clovaai/deep-text-recognition-benchmark.git\n",
        "%cd /content/deep-text-recognition-benchmark            # %cd persists in Colab sessions :contentReference[oaicite:2]{index=2}\n",
        "\n",
        "# If you kept the newest Torch, replace the broken import:\n",
        "!sed -i \"s/from torch._utils import _accumulate/from itertools import accumulate as _accumulate/\" dataset.py  # :contentReference[oaicite:3]{index=3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQwWgEHh8Iy1",
        "outputId": "cf8ed330-a8a3-40e7-eaf4-9ac6b5d8a965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✔️  wrote 517 lines  -> train.txt\n",
            "✔️  wrote 58 lines    -> val.txt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd, pathlib, random, math, os, textwrap\n",
        "\n",
        "DATA_ROOT = 'crops/crops'                # folder with images + ocr_data.csv\n",
        "CSV       = f'{DATA_ROOT}/ocr_data.csv'\n",
        "WORKDIR   = '/content/my_lmdb_work'\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(CSV)                       # needs columns: filename, words\n",
        "df['path'] = df['filename'].apply(lambda x: f'{DATA_ROOT}/{x}')\n",
        "df = df[df['path'].apply(lambda p: pathlib.Path(p).exists())]  # drop missing\n",
        "\n",
        "# split 90 / 10\n",
        "paths = df.sample(frac=1, random_state=42)  # shuffle\n",
        "cut   = math.floor(len(paths)*0.9)\n",
        "train_df, val_df = paths[:cut], paths[cut:]\n",
        "\n",
        "for name, subset in [('train',train_df), ('val',val_df)]:\n",
        "    with open(f'{WORKDIR}/{name}.txt','w') as f:\n",
        "        for _,r in subset.iterrows():\n",
        "            f.write(f\"{r['path']}\\t{r['words']}\\n\")\n",
        "print(textwrap.dedent(f\"\"\"\n",
        "    ✔️  wrote {len(train_df)} lines  -> train.txt\n",
        "    ✔️  wrote {len(val_df)} lines    -> val.txt\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTpB6QHuy9nG",
        "outputId": "64a60696-e3d6-4452-aa31-38ce09d35971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset with 517 samples\n",
            "Created dataset with 58 samples\n"
          ]
        }
      ],
      "source": [
        "!pip install -q fire lmdb\n",
        "\n",
        "# build training LMDB\n",
        "!python deep-text-recognition-benchmark/create_lmdb_dataset.py \\\n",
        "        --inputPath /content \\\n",
        "        --gtFile    /content/my_lmdb_work/train.txt \\\n",
        "        --outputPath /content/my_lmdb_work/lmdb_train               # :contentReference[oaicite:6]{index=6}\n",
        "\n",
        "# build validation LMDB\n",
        "!python deep-text-recognition-benchmark/create_lmdb_dataset.py \\\n",
        "        --inputPath /content \\\n",
        "        --gtFile    /content/my_lmdb_work/val.txt \\\n",
        "        --outputPath /content/my_lmdb_work/lmdb_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCCSqZwV18fS",
        "outputId": "03491066-4fc4-4c90-968e-46a14ac12409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-02 23:44:59--  https://github.com/clovaai/deep-text-recognition-benchmark/releases/download/0.1.0/TPS-ResNet-BiLSTM-Attn.pth\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-06-02 23:45:00 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/JaidedAI/EasyOCR/releases/download/pre-v1.1.6/craft_mlt_25k.zip\n",
        "!unzip craft_mlt_25k.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKu-k1jX3sOx",
        "outputId": "8bed5ede-a8c4-4520-f8c3-9e988085781d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: ./my_lmdb_work/lmdb_train\n",
            "opt.select_data: ['train']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    ./my_lmdb_work/lmdb_train\t dataset: train\n",
            "sub-directory:\t/.\t num samples: 517\n",
            "num total samples of train: 517 x 1.0 (total_data_usage_ratio) = 517\n",
            "num samples of train per batch: 192 x 1.0 (batch_ratio) = 192\n",
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 192 = 192\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    ./my_lmdb_work/lmdb_val\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 58\n",
            "--------------------------------------------------------------------------------\n",
            "model input parameters 32 100 20 1 512 256 12 25 TPS ResNet BiLSTM Attn\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
            "loading pretrained model from craft_mlt_25k.pth\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (Transformation): TPS_SpatialTransformerNetwork(\n",
            "      (LocalizationNetwork): LocalizationNetwork(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): ReLU(inplace=True)\n",
            "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (10): ReLU(inplace=True)\n",
            "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (14): ReLU(inplace=True)\n",
            "          (15): AdaptiveAvgPool2d(output_size=1)\n",
            "        )\n",
            "        (localization_fc1): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "        )\n",
            "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
            "      )\n",
            "      (GridGenerator): GridGenerator()\n",
            "    )\n",
            "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
            "      (ConvNet): ResNet(\n",
            "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer2): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "        (layer3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (layer4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
            "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
            "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Attention(\n",
            "      (attention_cell): AttentionCell(\n",
            "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
            "        (rnn): LSTMCell(268, 256)\n",
            "      )\n",
            "      (generator): Linear(in_features=256, out_features=12, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Trainable params num :  49521876\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "exp_name: crops_run\n",
            "train_data: ./my_lmdb_work/lmdb_train\n",
            "valid_data: ./my_lmdb_work/lmdb_val\n",
            "manualSeed: 1111\n",
            "workers: 2\n",
            "batch_size: 192\n",
            "num_iter: 500\n",
            "valInterval: 100\n",
            "saved_model: craft_mlt_25k.pth\n",
            "FT: True\n",
            "adam: False\n",
            "lr: 1\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "baiduCTC: False\n",
            "select_data: ['train']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 25\n",
            "imgH: 32\n",
            "imgW: 100\n",
            "rgb: False\n",
            "character: 0123456789\n",
            "sensitive: False\n",
            "PAD: False\n",
            "data_filtering_off: False\n",
            "Transformation: TPS\n",
            "FeatureExtraction: ResNet\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: Attn\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 512\n",
            "hidden_size: 256\n",
            "num_gpu: 1\n",
            "num_class: 12\n",
            "---------------------------------------\n",
            "\n",
            "[1/500] Train loss: 2.39707, Valid loss: 2.13740, Elapsed_time: 1.37430\n",
            "Current_accuracy : 0.000, Current_norm_ED  : 0.00\n",
            "Best_accuracy    : 0.000, Best_norm_ED     : 0.00\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "4                         |                           | 0.0000\tFalse\n",
            "5                         |                           | 0.0000\tFalse\n",
            "7                         |                           | 0.0000\tFalse\n",
            "2                         |                           | 0.0000\tFalse\n",
            "6                         |                           | 0.0000\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[100/500] Train loss: 0.83079, Valid loss: 0.44884, Elapsed_time: 28.24366\n",
            "Current_accuracy : 62.069, Current_norm_ED  : 0.66\n",
            "Best_accuracy    : 62.069, Best_norm_ED     : 0.66\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "2                         | 9                         | 0.4571\tFalse\n",
            "5                         | 5                         | 0.9806\tTrue\n",
            "4                         | 8                         | 0.4704\tFalse\n",
            "8                         | 8                         | 0.8844\tTrue\n",
            "5                         | 5                         | 0.9618\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[200/500] Train loss: 0.05067, Valid loss: 0.19618, Elapsed_time: 54.18368\n",
            "Current_accuracy : 86.207, Current_norm_ED  : 0.89\n",
            "Best_accuracy    : 86.207, Best_norm_ED     : 0.89\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "12                        | 12                        | 0.9943\tTrue\n",
            "119                       | 119                       | 0.9593\tTrue\n",
            "13                        | 13                        | 0.9872\tTrue\n",
            "7                         | 7                         | 0.9730\tTrue\n",
            "7                         | 7                         | 0.9619\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[300/500] Train loss: 0.00720, Valid loss: 0.19986, Elapsed_time: 79.49831\n",
            "Current_accuracy : 86.207, Current_norm_ED  : 0.89\n",
            "Best_accuracy    : 86.207, Best_norm_ED     : 0.89\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "2                         | 2                         | 0.6534\tTrue\n",
            "3                         | 3                         | 0.9972\tTrue\n",
            "5                         | 5                         | 0.9982\tTrue\n",
            "8                         | 9                         | 0.9875\tFalse\n",
            "9                         | 9                         | 0.9939\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "[400/500] Train loss: 0.00230, Valid loss: 0.20168, Elapsed_time: 104.50948\n",
            "Current_accuracy : 87.931, Current_norm_ED  : 0.89\n",
            "Best_accuracy    : 87.931, Best_norm_ED     : 0.89\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "8                         | 8                         | 0.9982\tTrue\n",
            "123                       | 123                       | 0.9968\tTrue\n",
            "119                       | 119                       | 0.9937\tTrue\n",
            "2                         | 2                         | 0.9995\tTrue\n",
            "7                         | 2                         | 0.5121\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "[500/500] Train loss: 0.00113, Valid loss: 0.19260, Elapsed_time: 129.88660\n",
            "Current_accuracy : 87.931, Current_norm_ED  : 0.89\n",
            "Best_accuracy    : 87.931, Best_norm_ED     : 0.89\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "5                         | 5                         | 0.9995\tTrue\n",
            "123                       | 123                       | 0.9982\tTrue\n",
            "123                       | 123                       | 0.9980\tTrue\n",
            "122                       | 122                       | 0.5970\tTrue\n",
            "5                         | 5                         | 0.9984\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "end the training\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.26.4\n",
        "!python deep-text-recognition-benchmark/train.py --valInterval 100 --num_iter 500 \\\n",
        "  --exp_name 'crops_run' \\\n",
        "  --train_data ./my_lmdb_work/lmdb_train --valid_data ./my_lmdb_work/lmdb_val \\\n",
        "  --select_data 'train' --batch_ratio 1 \\\n",
        "  --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "  --batch_size 192 --workers 2 \\\n",
        "  --imgH 32 --imgW 100 \\\n",
        "  --batch_max_length 25 \\\n",
        "  --character \"0123456789\" \\\n",
        "  --saved_model craft_mlt_25k.pth --FT\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}